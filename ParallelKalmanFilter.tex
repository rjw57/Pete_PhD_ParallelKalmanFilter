\documentclass{article}

\usepackage{amsmath}
\usepackage{IEEEtrantools}


%opening
\title{Parallel Batch Kalman Filtering}
\author{Pete Bunch}

\begin{document}
\maketitle

\section{Introduction}

Sometimes we want to run a Kalman filter offline, for example when using Rao-Blackwellisation in an MCMC algorithm, such as the MCMC-DA system for target tracking. In this case, the sequential nature of the Kalman filter prevents it from being easily parallelisable. Here we try to fix that.

\section{System Equations}

Consider a standard discrete-time linear-Gaussian state-space model,
%
\begin{IEEEeqnarray}{rCl}
 x_n & = & A x_{n-1} + w_n \\
 y_n & = & C x_n + v_n
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
 w_n & \sim & \mathcal{N}(.|0, Q) \\
 v_n & \sim & \mathcal{N}(.|0, R)     .
\end{IEEEeqnarray}

For now, we assume that the starting state, $x_0$ is fixed and known. We'll want to relax this condition later.

We can stack up all $N$ of the state and observation equations into matrix equations,
%
\begin{IEEEeqnarray}{rCl}
 \underbrace{\begin{bmatrix}x_1 \\ x_2 \\ x_3 \\ \vdots \\ x_N \end{bmatrix}}_{X} & = & \underbrace{\begin{bmatrix}A \\ A^2 \\ A^3 \\ \vdots \\ A^N \end{bmatrix}}_{F} x_0 + \underbrace{\begin{bmatrix} I & 0 & 0 & \hdots & 0 \\ A & I & 0 & \hdots & 0 \\ A^2 & A & I & \hdots & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots \\ A^N & A^{N-1} & A^{N-2} & \hdots & I \end{bmatrix}}_{G} \underbrace{\begin{bmatrix} w_1 \\ w_2 \\ w_3 \\ \vdots \\ w_N \end{bmatrix}}_{W}
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
 \underbrace{\begin{bmatrix}y_1 \\ \vdots \\ y_N \end{bmatrix}}_{Y} & = & \underbrace{\begin{bmatrix}C & & \\ & \ddots & \\ & & C \end{bmatrix}}_{H} \underbrace{\begin{bmatrix}x_1 \\ \vdots \\ x_N \end{bmatrix}}_{X} + \underbrace{\begin{bmatrix} v_1 \\ \vdots \\ v_N \end{bmatrix}}_{V}     .
\end{IEEEeqnarray}
\begin{IEEEeqnarray}{rCl}
 W & \sim & \mathcal{N}\left(.|0, \underbrace{\begin{bmatrix}Q & & \\ & \ddots & \\ & & Q \end{bmatrix}}_{S} \right) \\
 C & \sim & \mathcal{N}\left(.|0, \underbrace{\begin{bmatrix}R & & \\ & \ddots & \\ & & R \end{bmatrix}}_{T} \right)     .
\end{IEEEeqnarray}

This gives us the following distributions,
%
\begin{IEEEeqnarray}{rCl}
 X & \sim & \mathcal{N}(.|F x_0,GSG^T) \\
 Y & \sim & \mathcal{N}(.|H X,T)     .
\end{IEEEeqnarray}

Now its time for Bayes,
%
\begin{IEEEeqnarray}{rCl}
 P(X|Y) & = & \frac{P(Y|X)P(X)}{P(Y)} \\
        & = & \mathcal{N}(X|\mu,\Sigma)     .
\end{IEEEeqnarray}

For completeness, here's the derivation of $\mu$ and $\Sigma$ in full. Its pretty standard completing the square, throughout which we though away constant terms knowing that they'll come out in the wash when we normalise.
%
\begin{IEEEeqnarray*}{rCl}
 P(X|Y) & \propto & P(Y|X) P(X) \\
        & = & \mathcal{N}(X|F x_0,GSG^T) \mathcal{N}(Y|H X,T) \\
        & \propto & \exp\left\{ -\frac{1}{2} \left[ (X-F x_0)^T (GSG^T)^{-1} (X-F x_0) + (Y-H X)^T T^{-1} (Y-H X) \right] \right\} \\
        & \propto & \exp\left\{ -\frac{1}{2} \left[ X^T (GSG^T)^{-1} X - 2x_0^T F^T (GSG^T)^{-1} X + X^T H^T T^{-1} H X - 2 Y^T T^{-1} H X \right] \right\} \\
        & \propto & \exp\left\{ -\frac{1}{2} \left[ X^T \left( (GSG^T)^{-1} + H^T T^{-1} H \right) X - 2 \left( x_0^T F^T (GSG^T)^{-1} + Y^T T^{-1} H \right) X \right] \right\} \\
        & \propto & \exp\left\{ -\frac{1}{2} \left[ X^T \Sigma^{-1} X - 2 \mu^T \Sigma^{-1} X \right] \right\}     .
\end{IEEEeqnarray*}

Comparing terms gives us,
\begin{IEEEeqnarray}{rCl}
 \Sigma & = & \left[ (GSG^T)^{-1} + H^T T^{-1} H \right]^{-1} \\
 \mu    & = & \Sigma \left[ (GSG^T)^{-1} F x_0 + H^T T^{-1} Y \right]     .
\end{IEEEeqnarray}

Good. $\mu$ is the vector of posterior means for each state. $\Sigma$ is the complete covariance matrix for all states over time. To replicate a Kalman smoother, we only need the blocks on the diagonal of this matrix. The other blocks are the covariances between states at different times, and are less interesting.

$\Sigma^{-1}$ is highly structured, and in fact we can right is out explicitly. $G$ is square and clearly full rank (because $A$ has to be full rank for a valid HMM), and it turns out that its inverse has the following wizard form,
%
\begin{IEEEeqnarray}{rCl}
 G^{-1} & = & \begin{bmatrix} I & 0 & 0 & \hdots & 0 & 0 \\ -A & I & 0 & \hdots & 0 & 0 \\ 0 & -A & I & \vdots & 0 & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & 0 & \hdots & I & 0 \\ 0 & 0 & 0 & \hdots & -A & I \end{bmatrix}     .
\end{IEEEeqnarray}

Thus we can write,
%
\begin{IEEEeqnarray}{rCl}
 \Sigma^{-1} & = & G^{-T} S^{-1} G^{-1} + H^T T^{-1} H \nonumber \\
             & = & \begin{bmatrix} Q^{-1} + A^T Q^{-1} A & -A^T Q^{-1} & 0 & \hdots & 0 & 0 \\ -Q^{-1}A & Q^{-1} + A^T Q^{-1} A & -A^T Q^{-1} & \hdots & 0 & 0 \\ 0 & -Q^{-1}A & Q^{-1} + A^T Q^{-1} A & \vdots & 0 & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & 0 & \hdots & Q^{-1} + A^T Q^{-1} A & -A^T Q^{-1} \\ 0 & 0 & 0 & \hdots & -Q^{-1}A & Q^{-1} \end{bmatrix} \nonumber \\
             &   & + \: \begin{bmatrix} C^T R^{-1} C & 0 & 0 & \hdots & 0 & 0 \\ 0 & C^T R^{-1} C & 0 & \hdots & 0 & 0 \\ 0 & 0 & C^T R^{-1} C & \vdots & 0 & 0 \\ \vdots & \vdots & \vdots & \ddots & \vdots & \vdots \\ 0 & 0 & 0 & \hdots & C^T R^{-1} C & 0 \\ 0 & 0 & 0 & \hdots & 0 & C^T R^{-1} C \end{bmatrix}
\end{IEEEeqnarray}


The tasks that remain then are as follows:
\begin{itemize}
  \item Evaluate the vector $\xi = \left[ (GSG^T)^{-1} F x_0 + H^T T^{-1} Y \right]$. Since $(GSG^T)^{-1}$ has a simple
      form, this can be done in $O(N)$ time and is embarassingly parallel.
  \item Calculate the diagonal blocks of $\Sigma$ to give the individual covariances.
  \item Solve the system of equations $\Sigma^{-1} \mu = \xi$ to give us $\mu$.
\end{itemize}
It is these last two operations which must run in $O(NM^3)$ time to equal the complexity of the Kalman filter. Ideally
they should be parallelisable in $N$ making the overall parallel algorithm $O(M^3)$.

Define the matrices $D \equiv A^TQ^{-1}A + C^T R^{-1} C$, $E \equiv Q^{-1} + D$ and $F \equiv -Q^{-1}A$. We may thus re-write
%
\begin{IEEEeqnarray}{rCl}
 \Sigma^{-1} & = & 
    \begin{bmatrix}
        E & F^T & 0   & \hdots & 0 & 0 \\
        F & E   & F^T & \hdots & 0 & 0 \\
        0 & F   & E   & \ddots & 0 & 0 \\
        \vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
        0 & 0 & 0 & \ddots & E & F^T \\
        0 & 0 & 0 & \hdots & F & Q^{-1} \\
    \end{bmatrix}
\end{IEEEeqnarray}
Let $M$ be the size of matrices $F$ and $E$ such that they are both $M \times M$ matrices and $N$ be the number of
blocks in $\Sigma^{-1}$ suck that $\Sigma^{-1}$ is $MN \times MN$. If we define the $MN \times MN$ block circulant matrix
%
\begin{IEEEeqnarray}{rCl}
 C & = & 
    \begin{bmatrix}
        E & F^T & 0   & \hdots & 0 & F \\
        F & E   & F^T & \hdots & 0 & 0 \\
        0 & F   & E   & \ddots & 0 & 0 \\
        \vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
        0 & 0 & 0 & \ddots & E & F^T \\
        F^T & 0 & 0 & \hdots & F & E \\
    \end{bmatrix}
\end{IEEEeqnarray}
and $MN \times MN$ matrix
\begin{IEEEeqnarray}{rCl}
 \Delta & = & 
    \begin{bmatrix}
        0 & 0 & \hdots & 0 & F \\
        0 & 0 & \hdots & 0 & 0 \\
        \vdots & \vdots & \ddots & \vdots & \vdots \\
        0 & 0 & \hdots & 0 & 0 \\
        F^T & 0 & \hdots & 0 & D \\
    \end{bmatrix}
\end{IEEEeqnarray}
then $\Sigma^{-1} = C - \Delta$. The matrix $\Delta$ factorises into $\Delta = UV^T$ where
\begin{equation}
    U = \begin{bmatrix} I & 0 \\ 0 & 0 \\ 0 & F^T \end{bmatrix}, \quad
    V^T = \begin{bmatrix} 0 & 0 & F \\ I & 0 & F^{-T} D \end{bmatrix}
\end{equation}
and $U$ and $V$ are $MN \times 2M$. Via the Woodbury identity:
\begin{IEEEeqnarray}{rCl}
    \Sigma & = & (C - UV^T)^{-1} \\
           & = & C^{-1} + C^{-1}U(1-V^TC^{-1}U)^{-1}V^TC^{-1}
\end{IEEEeqnarray}
The value $V^TC^{-1}U$ may be found directly. Since $C$ is block circulant and symmetric, so will $C^{-1}$ be. Label the 
blocks as follows:
\begin{equation}
    C^{-1} =
    \begin{bmatrix}
        C^{-1}_0 & C^{-1}_{1} & \hdots & C^{-1}_{N-1} \\
        C^{-1}_{N-1} & C^{-1}_{0} & \hdots & C^{-1}_{N-2} \\
        \vdots & \vdots & \ddots & \vdots \\
        C^{-1}_1 & C^{-1}_{2} & \hdots & C^{-1}_{0}
    \end{bmatrix}
\end{equation}
where the $i, j$-th block of $C^{-1}$ is labeled $C_{N+j-i \mbox{ mod } N}$.
Note that $C^{-1}_i$ is the transpose of $C^{-1}_{N-i}$ and hence
\begin{IEEEeqnarray}{rCl}
    I - V^TC^{-1}U & = &
        I - \begin{bmatrix} 0 & 0 & F \\ I & 0 & F^{-T} D \end{bmatrix}
        \begin{bmatrix}
            C^{-1}_{0} & \hdots & C^{-1}_{N-1} \\ \vdots & \ddots & \vdots \\ C^{-1}_{1} & \hdots & C^{-1}_{0}
        \end{bmatrix}
        \begin{bmatrix} I & 0 \\ 0 & 0 \\ 0 & F^T \end{bmatrix} \\
               & = &
        I -\begin{bmatrix} 0 & 0 & F \\ I & 0 & F^{-T} D \end{bmatrix}
        \begin{bmatrix}
            C^{-1}_{0} & C^{-1}_{N-1} F^T \\
            \vdots & \vdots \\
            C^{-1}_{1} & C^{-1}_{0} F^T
        \end{bmatrix} \\
               & = &
        I - \begin{bmatrix}
            F C^{-1}_{1} & F C^{-1}_{0} F^T \\
            C^{-1}_{0} + F^{-T}D C^{-1}_{1} & C^{-1}_{N-1} F^T + F^{-T}D C^{-1}_{0} F^T
        \end{bmatrix} \\
               & = &
        \begin{bmatrix}
            I - F C^{-1}_{1} & - F C^{-1}_{0} F^T \\
            - C^{-1}_{0} - F^{-T}D C^{-1}_{1} & I - (C^{-1}_1)^T F^T - F^{-T}D C^{-1}_{0} F^T
        \end{bmatrix} 
\end{IEEEeqnarray}
which is $2M \times 2M$. Since $C$ is block circulant, its inverse will also be block circulant and so it is sufficient
to solve the following system:
\begin{IEEEeqnarray}{rCl}
    \underbrace{\begin{bmatrix} I \\ 0 \\ 0 \\ \vdots \\ 0 \\ 0 \end{bmatrix}}_{MN \times M} & = &
    \underbrace{\begin{bmatrix}
        E & F^T & 0   & \hdots & 0 & F \\
        F & E   & F^T & \hdots & 0 & 0 \\
        0 & F   & E   & \ddots & 0 & 0 \\
        \vdots & \vdots & \ddots & \ddots & \ddots & \vdots \\
        0 & 0 & 0 & \ddots & E & F^T \\
        F^T & 0 & 0 & \hdots & F & E \\
    \end{bmatrix}}_{MN \times MN}
        \underbrace{\begin{bmatrix}
            C^{-1}_{0} \\ 
            C^{-1}_{1} \\ 
            \vdots \\
            C^{-1}_{N-1}
            \end{bmatrix}}_{MN \times M}.
\end{IEEEeqnarray}

De Mazancourt and Gerlic show that this may be solved sequentially in $O(NM^3)$ time.

Let the matrix $(I - V^T C^{-1} U)^{-1}$ have the following $M \times M$ blocks:
\begin{equation}
    (I - V^T C^{-1} U)^{-1} = \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix}.
\end{equation}
then
\begin{IEEEeqnarray}{rCl}
    U \begin{bmatrix} \alpha & \beta \\ \gamma & \delta \end{bmatrix} V^T & = &
        U \begin{bmatrix}
            \beta & 0 & \hdots & 0 & \alpha F + \beta F^{-T}D \\
            \delta & 0 & \hdots & 0 & \gamma F + \delta F^{-T}D
        \end{bmatrix} \\
        & = &
        \begin{bmatrix}
            \beta & 0 & \hdots & 0 & \alpha F + \beta F^{-T}D \\
            0 & 0 & \hdots & 0 & 0\\
            \vdots & \vdots & \ddots & \vdots & \vdots \\
            0 & 0 & \hdots & 0 & 0\\
            F^T \delta & 0 & \hdots & 0 & F^T \gamma F + F^T \delta F^{-T}D
        \end{bmatrix}
\end{IEEEeqnarray}
so, if $M = C^{-1}U(1-V^TC^{-1}U)^{-1}V^TC^{-1} $, then
\begin{IEEEeqnarray}{rCl}
    M & = &
        C^{-1} \begin{bmatrix}
            \beta & 0 & \hdots & 0 & \alpha F + \beta F^{-T}D \\
            0 & 0 & \hdots & 0 & 0\\
            \vdots & \vdots & \ddots & \vdots & \vdots \\
            0 & 0 & \hdots & 0 & 0\\
            F^T \delta & 0 & \hdots & 0 & F^T \gamma F + F^T \delta F^{-T}D
        \end{bmatrix} C^{-1} \\
    & = &
        C^{-1} \begin{bmatrix}
            M_{11} & 0 & \hdots & 0 & M_{12} \\
            0 & 0 & \hdots & 0 & 0\\
            \vdots & \vdots & \ddots & \vdots & \vdots \\
            0 & 0 & \hdots & 0 & 0\\
            M_{21} & 0 & \hdots & 0 & M_{22} \\
        \end{bmatrix} C^{-1} \\
    & = &
        C^{-1} \begin{bmatrix}
            M_{11} C^{-1}_0 + M_{12} C^{-1}_{1} & \hdots  &
                M_{11} C^{-1}_{j-1} + M_{12} C^{-1}_{j} & \hdots \\
            0 \\
            \vdots \\
            0 \\
            M_{21} C^{-1}_0 + M_{22} C^{-1}_{1} & \hdots  &
                M_{21} C^{-1}_{j-1} + M_{22} C^{-1}_{j} & \hdots \\
        \end{bmatrix} 
\end{IEEEeqnarray}
so the $i j$-th block of $M$ will be
\begin{IEEEeqnarray}{rCl}
    M_{ij} & = & 
    C^{-1}_{N - i + 1 \mbox{ mod } N} ( M_{11} C^{-1}_{j-1} + M_{12} C^{-1}_{j} ) +
    C^{-1}_{N - i} ( M_{21} C^{-1}_{j-1} + M_{22} C^{-1}_{j}  ) \nonumber \\
    & = &
    (C^{-1}_{i-1})^T ( M_{11} C^{-1}_{j-1} + M_{12} C^{-1}_{j} ) + 
    (C^{-1}_{i})^T ( M_{21} C^{-1}_{j-1} + M_{22} C^{-1}_{j}  ) \nonumber \\
    & \equiv &
    \begin{bmatrix}
        C^{-1}_{i-1} \\ C^{-1}_{i}
    \end{bmatrix}^T
    \begin{bmatrix}
        M_{11} & M_{12} \\ M_{21} & M_{22} \\
    \end{bmatrix}
    \begin{bmatrix}
        C^{-1}_{j-1} \\ C^{-1}_{j}
    \end{bmatrix}
\end{IEEEeqnarray}
and hence the $i, j$-th block of $\Sigma$ will be
\begin{IEEEeqnarray}{rCl}
    \Sigma_{ij} = C^{-1}_{N+j-i \mbox{ mod } N} +
    \begin{bmatrix}
        C^{-1}_{i-1} \\ C^{-1}_{i}
    \end{bmatrix}^T
    \begin{bmatrix}
        M_{11} & M_{12} \\ M_{21} & M_{22} \\
    \end{bmatrix}
    \begin{bmatrix}
        C^{-1}_{j-1} \\ C^{-1}_{j}
    \end{bmatrix}
\end{IEEEeqnarray}
and the $k$-th diagonal block will be
\begin{IEEEeqnarray}{rCl}
    \Sigma_{k} = C^{-1}_{0} +
    \begin{bmatrix}
        C^{-1}_{k-1} \\ C^{-1}_{k}
    \end{bmatrix}^T
    \begin{bmatrix}
        M_{11} & M_{12} \\ M_{21} & M_{22} \\
    \end{bmatrix}
    \begin{bmatrix}
        C^{-1}_{k-1} \\ C^{-1}_{k}
    \end{bmatrix}
\end{IEEEeqnarray}

\end{document}

